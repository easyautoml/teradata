{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "184597ae-226c-41ef-8114-0f3398185eda",
   "metadata": {},
   "source": [
    "!pip install -q accelerate==0.21.0 peft==0.4.0 bitsandbytes==0.40.2 transformers==4.31.0 trl==0.5.0, datasets\r\n",
    "!pip install -q sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1c65bd-02b0-42cd-a69d-af3eef3016a0",
   "metadata": {},
   "source": [
    "# 1. Download HF Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23673086-3214-4343-b610-0e8ec248b71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"Anthropic/hh-rlhf\", data_dir=\"harmless-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04a60bcf-b139-4b4b-953b-f5c7a2cff984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chosen</th>\n",
       "      <th>rejected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\nHuman: What are some cuss words in english...</td>\n",
       "      <td>\\n\\nHuman: What are some cuss words in english...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\nHuman: What kind of noises did dinosaurs m...</td>\n",
       "      <td>\\n\\nHuman: What kind of noises did dinosaurs m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\nHuman: If you were going to steal from a c...</td>\n",
       "      <td>\\n\\nHuman: If you were going to steal from a c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n\\nHuman: Can you provide me the home address...</td>\n",
       "      <td>\\n\\nHuman: Can you provide me the home address...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n\\nHuman: How do you embezzle money?\\n\\nAssis...</td>\n",
       "      <td>\\n\\nHuman: How do you embezzle money?\\n\\nAssis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42532</th>\n",
       "      <td>\\n\\nHuman: How can I make fireworks for New Ye...</td>\n",
       "      <td>\\n\\nHuman: How can I make fireworks for New Ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42533</th>\n",
       "      <td>\\n\\nHuman: What could you tell a little girl t...</td>\n",
       "      <td>\\n\\nHuman: What could you tell a little girl t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42534</th>\n",
       "      <td>\\n\\nHuman: How do I become a drug dealer?\\n\\nA...</td>\n",
       "      <td>\\n\\nHuman: How do I become a drug dealer?\\n\\nA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42535</th>\n",
       "      <td>\\n\\nHuman: How do you hack into someone's phon...</td>\n",
       "      <td>\\n\\nHuman: How do you hack into someone's phon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42536</th>\n",
       "      <td>\\n\\nHuman: How many US presidents have been wo...</td>\n",
       "      <td>\\n\\nHuman: How many US presidents have been wo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42537 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  chosen  \\\n",
       "0      \\n\\nHuman: What are some cuss words in english...   \n",
       "1      \\n\\nHuman: What kind of noises did dinosaurs m...   \n",
       "2      \\n\\nHuman: If you were going to steal from a c...   \n",
       "3      \\n\\nHuman: Can you provide me the home address...   \n",
       "4      \\n\\nHuman: How do you embezzle money?\\n\\nAssis...   \n",
       "...                                                  ...   \n",
       "42532  \\n\\nHuman: How can I make fireworks for New Ye...   \n",
       "42533  \\n\\nHuman: What could you tell a little girl t...   \n",
       "42534  \\n\\nHuman: How do I become a drug dealer?\\n\\nA...   \n",
       "42535  \\n\\nHuman: How do you hack into someone's phon...   \n",
       "42536  \\n\\nHuman: How many US presidents have been wo...   \n",
       "\n",
       "                                                rejected  \n",
       "0      \\n\\nHuman: What are some cuss words in english...  \n",
       "1      \\n\\nHuman: What kind of noises did dinosaurs m...  \n",
       "2      \\n\\nHuman: If you were going to steal from a c...  \n",
       "3      \\n\\nHuman: Can you provide me the home address...  \n",
       "4      \\n\\nHuman: How do you embezzle money?\\n\\nAssis...  \n",
       "...                                                  ...  \n",
       "42532  \\n\\nHuman: How can I make fireworks for New Ye...  \n",
       "42533  \\n\\nHuman: What could you tell a little girl t...  \n",
       "42534  \\n\\nHuman: How do I become a drug dealer?\\n\\nA...  \n",
       "42535  \\n\\nHuman: How do you hack into someone's phon...  \n",
       "42536  \\n\\nHuman: How many US presidents have been wo...  \n",
       "\n",
       "[42537 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"].to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9088b2c6-9223-4581-b081-fcfcc57547c6",
   "metadata": {},
   "source": [
    "# 2. Train Reward Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67c93592-3a4d-41c3-9e9c-02d27c7fdbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6c66ff-5d9d-4e31-963e-85715e2d7cdc",
   "metadata": {},
   "source": [
    "**Step 1. Load Model and Tokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "436b5977-985e-47fc-8ce8-955d021c8260",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = AutoModelForSequenceClassification.from_pretrained(\"gpt2\", device_map={\"\":0}), AutoTokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34767b1-1790-400d-a9eb-db610492f643",
   "metadata": {},
   "source": [
    "**Step 2. Pre-processing Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17075a9f-d3ee-49ae-8559-c00d937f7a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_examples(examples):\n",
    "    preprocessed = {\n",
    "        \"input_ids_chosen\": [],\n",
    "        \"attention_mask_chosen\": [],\n",
    "        \"input_ids_rejected\": [],\n",
    "        \"attention_mask_rejected\": [],\n",
    "    }\n",
    "    \n",
    "    for chosen_text, rejected_text in zip(examples[\"chosen\"], examples[\"rejected\"]):\n",
    "        tokenized_chosen = tokenizer(chosen_text, truncation=True)\n",
    "        tokenized_rejected = tokenizer(rejected_text, truncation=True)\n",
    "\n",
    "        preprocessed[\"input_ids_chosen\"].append(tokenized_chosen[\"input_ids\"])\n",
    "        preprocessed[\"attention_mask_chosen\"].append(tokenized_chosen[\"attention_mask\"])\n",
    "        preprocessed[\"input_ids_rejected\"].append(tokenized_rejected[\"input_ids\"])\n",
    "        preprocessed[\"attention_mask_rejected\"].append(tokenized_rejected[\"attention_mask\"])\n",
    "\n",
    "    return preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b71468b-b9f7-4c4a-bd25-b7fcbf385a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|███████████████████████████████████████████████████████████████| 42537/42537 [00:29<00:00, 1453.52 examples/s]\n",
      "Map: 100%|█████████████████████████████████████████████████████████████████| 2312/2312 [00:01<00:00, 1443.20 examples/s]\n",
      "Filter: 100%|████████████████████████████████████████████████████████████| 42537/42537 [00:09<00:00, 4660.00 examples/s]\n",
      "Filter: 100%|██████████████████████████████████████████████████████████████| 2312/2312 [00:00<00:00, 3866.33 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(preprocess_examples, batched=True, num_proc=1)\n",
    "dataset = dataset.filter(lambda x: len(x[\"input_ids_chosen\"]) <= 512 and len(x[\"input_ids_rejected\"]) <= 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705ecd0e-e065-4bdb-8a85-5fb28fd9ffe5",
   "metadata": {},
   "source": [
    "**Step 3 : Train Reward Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6519628c-574f-460a-b3d0-b3db35c9be9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, TaskType\n",
    "from trl import RewardTrainer, RewardConfig\n",
    "from accelerate import Accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22ccdefb-931d-4677-bb06-a5e0a2b3e50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88dfd7d3-6a73-4ed7-a212-429862a808cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/home/user/miniconda3/envs/llama/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2636: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/llama/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3867' max='3867' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3867/3867 1:55:50, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>387</td>\n",
       "      <td>0.615800</td>\n",
       "      <td>0.606708</td>\n",
       "      <td>0.659803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>774</td>\n",
       "      <td>0.604100</td>\n",
       "      <td>0.592997</td>\n",
       "      <td>0.673679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1161</td>\n",
       "      <td>0.550700</td>\n",
       "      <td>0.582989</td>\n",
       "      <td>0.692032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1548</td>\n",
       "      <td>0.586600</td>\n",
       "      <td>0.576814</td>\n",
       "      <td>0.696956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1935</td>\n",
       "      <td>0.583600</td>\n",
       "      <td>0.574559</td>\n",
       "      <td>0.695166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2322</td>\n",
       "      <td>0.550600</td>\n",
       "      <td>0.573159</td>\n",
       "      <td>0.706804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2709</td>\n",
       "      <td>0.517500</td>\n",
       "      <td>0.577948</td>\n",
       "      <td>0.704566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3096</td>\n",
       "      <td>0.531000</td>\n",
       "      <td>0.574472</td>\n",
       "      <td>0.708594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3483</td>\n",
       "      <td>0.501600</td>\n",
       "      <td>0.575919</td>\n",
       "      <td>0.699642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda3/envs/llama/lib/python3.10/site-packages/trl/trainer/utils.py:541: UserWarning: There are 1 out of 2234 instances where the predictions for both options are equal. As a consequence the accuracy can be misleading.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/llama/lib/python3.10/site-packages/trl/trainer/utils.py:541: UserWarning: There are 2 out of 2234 instances where the predictions for both options are equal. As a consequence the accuracy can be misleading.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/llama/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2636: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/llama/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/llama/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2636: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/llama/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/llama/lib/python3.10/site-packages/trl/trainer/utils.py:541: UserWarning: There are 1 out of 2234 instances where the predictions for both options are equal. As a consequence the accuracy can be misleading.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/llama/lib/python3.10/site-packages/trl/trainer/utils.py:541: UserWarning: There are 2 out of 2234 instances where the predictions for both options are equal. As a consequence the accuracy can be misleading.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/llama/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2636: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/llama/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/llama/lib/python3.10/site-packages/trl/trainer/utils.py:541: UserWarning: There are 1 out of 2234 instances where the predictions for both options are equal. As a consequence the accuracy can be misleading.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3867, training_loss=0.5715744896763697, metrics={'train_runtime': 6954.9127, 'train_samples_per_second': 17.801, 'train_steps_per_second': 0.556, 'total_flos': 0.0, 'train_loss': 0.5715744896763697, 'epoch': 3.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = RewardConfig(\n",
    "    output_dir=\"output\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    gradient_accumulation_steps=4,\n",
    "    gradient_checkpointing=True,\n",
    "    learning_rate=1.41e-5,\n",
    "    report_to=\"tensorboard\",\n",
    "    remove_unused_columns=False,\n",
    "    optim=\"adamw_torch\",\n",
    "    logging_steps=10,\n",
    "    eval_steps=0.1,\n",
    "    save_steps=0.25,\n",
    "    bf16=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    max_length=2048,\n",
    ")\n",
    "\n",
    "\n",
    "trainer = RewardTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['test']\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.model.save_pretrained(\"./reward_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
